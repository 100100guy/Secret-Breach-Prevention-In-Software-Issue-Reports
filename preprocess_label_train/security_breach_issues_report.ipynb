{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UiM0P-1Z0-f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import gensim\n",
        "import sklearn.metrics\n",
        "import re\n",
        "import unicodedata\n",
        "from tqdm import tqdm\n",
        "import sys\n",
        "import hashlib\n",
        "import random\n",
        "\n",
        "# train_file = 'nlbse23-issue-classification-train.csv'\n",
        "# test_file = 'nlbse23-issue-classification-test.csv'\n",
        "\n",
        "# csv.field_size_limit(sys.maxsize) # to avoid error: _csv.Error: field larger than field limit (131072)\n",
        "\n",
        "# def count_csv_rows(filename):\n",
        "# \twith open(filename, \"r\", newline='', encoding='utf-8') as f:\n",
        "# \t\treturn sum(1 for _ in csv.DictReader(f))\n",
        "\n",
        "# def print_csv_preview(filename):\n",
        "# \tprint(filename)\n",
        "# \tprint(\"total rows\", count_csv_rows(filename))\n",
        "# \tdisplay(pd.read_csv(filename, nrows=5))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rs39dE5DBjd",
        "outputId": "df60ff32-4753-4731-ac09-b714c237ee35"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 747
        },
        "id": "Y1E5U9eIZ0-g",
        "outputId": "5e45a614-9c9a-41d0-d271-34e34b0f9ea5"
      },
      "outputs": [],
      "source": [
        "# # download the training set if it does not exist\n",
        "# if not os.path.isfile(train_file):\n",
        "#   !curl \"https://tickettagger.blob.core.windows.net/datasets/{train_file}.tar.gz\" | tar -xz\n",
        "\n",
        "# print_csv_preview(train_file)\n",
        "\n",
        "# if not os.path.isfile(test_file):\n",
        "#   !curl \"https://tickettagger.blob.core.windows.net/datasets/{test_file}.tar.gz\" | tar -xz\n",
        "\n",
        "# print_csv_preview(test_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRhY_6vCbDCS"
      },
      "outputs": [],
      "source": [
        "# train_df = pd.read_csv(train_file)\n",
        "# test_df = pd.read_csv(test_file)\n",
        "#  concatenated_df = pd.concat([train_df,test_df])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWfLNxoK25TY",
        "outputId": "35d948c0-961d-408e-b223-ad4a271958d1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import re\n",
        "concatenated_df = pd.read_csv(\"nlbse-2023-issue-report.csv\")\n",
        "concatenated_df.shape\n",
        "df = concatenated_df[concatenated_df['labels']=='bug']\n",
        "print(df.shape)\n",
        "df_unique = df.drop_duplicates(subset='id', keep='first')\n",
        "print(df_unique.shape)\n",
        "df = df_unique\n",
        "df[\"id\"] = df[\"id\"].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "i7qAEyA5cB5J"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from collections import Counter\n",
        "\n",
        "def shannon_entropy(string):\n",
        "    # Calculate the frequency of each character in the string\n",
        "    freq = Counter(string)\n",
        "    \n",
        "    # Calculate the total number of characters in the string\n",
        "    total_chars = len(string)\n",
        "    \n",
        "    # Calculate the Shannon entropy\n",
        "    entropy = 0\n",
        "    for char, count in freq.items():\n",
        "        probability = count / total_chars\n",
        "        entropy -= probability * math.log2(probability)\n",
        "    \n",
        "    return entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQ3q_Oontq2X"
      },
      "outputs": [],
      "source": [
        "# regex_pattern = r'secret(?!$)'\n",
        "# p = re.compile(regex_pattern)\n",
        "# secret_df = df[[try_search(p, x) for x in df['body']]]\n",
        "# secret_df['body'].to_csv('secret_df.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YCvlQtYKsHkI"
      },
      "outputs": [],
      "source": [
        "# !pip3 install openpyxl \n",
        "excel_data = pd.read_excel('Secret Regular Expression.xlsx')\n",
        "\n",
        "# Read the values of the file in the dataframe\n",
        "regex = pd.DataFrame(excel_data, columns=[\n",
        "'Pattern_ID','Secret Type',\t'Regular Expression','Source'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "data_dict={}\n",
        "for j in df.index:\n",
        "        # if df[\"id\"][j] != \"1165939311\":\n",
        "        #         continue\n",
        "        input_string =    str(df[\"body\"][j])    \n",
        "        input_string = re.sub(r'[\\'\"\\â”‚]', '', input_string)\n",
        "        dir_list_clean = re.sub(r'drwx[-\\s]*\\d+\\s+\\w+\\s+\\w+\\s+\\d+\\s+\\w+\\s+\\d+\\s+[0-9a-fA-F-]+.*','',input_string)\n",
        "        shell_code_free_text = re.sub(r'```shell([^`]+)```','',dir_list_clean,flags=re.IGNORECASE)\n",
        "        shell_code_free_text = re.sub(r'```Shell\\s*\"([^\"]*)\"\\s*```','',shell_code_free_text,flags=re.IGNORECASE)\n",
        "        # saved_game_free_text = re.sub(r'```([^`]+)```','',shell_code_free_text) #etay jhamela hobe\n",
        "        saved_game_free_text = re.sub(r'<details><summary>Saved game</summary>\\n\\n```(.*?)```', '', shell_code_free_text)\n",
        "        remove_packages = re.sub(r'(\\w+\\.)+\\w+','',saved_game_free_text)\n",
        "        java_exp_free_text = re.sub(r'at\\s[\\w.$]+\\.([\\w]+)\\(([^:]+:\\d+)\\)','',remove_packages)\n",
        "        # url_free_text= re.sub(https?://[^\\s#]+#[A-Za-z0-9\\-]+,'', java_exp_free_text, flags=re.IGNORECASE)\n",
        "        url_with_fragment_text= re.sub(r'https?://[^\\s#]+#[A-Za-z0-9\\-\\=\\+]+','', java_exp_free_text, flags=re.IGNORECASE)\n",
        "        url_free_text= re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '',url_with_fragment_text)\n",
        "        commit_free_text= re.sub(r'commit[ ]?(?:id)?[ ]?[:]?[ ]?([0-9a-f]{40})\\b', '', url_free_text, flags=re.IGNORECASE)\n",
        "        file_path_free_text = re.sub(r\"/[\\w/. :-]+\",'',commit_free_text)\n",
        "        file_path_free_text = re.sub( r'(/[^/\\s]+)+','',file_path_free_text)\n",
        "        sha256_free_text = re.sub(r'sha256\\s*[:]?[=]?\\s*[a-fA-F0-9]{64}','',file_path_free_text)\n",
        "        sha1_free_text = re.sub(r'git-tree-sha1\\s*=\\s*[a-fA-F0-9]+','',sha256_free_text)\n",
        "        build_id_free_text = re.sub(r'build-id\\s*[:]?[=]?\\s*([a-fA-F0-9]+)','',sha1_free_text)\n",
        "        guids_free_text = re.sub(r'GUIDs:\\s+([0-9a-fA-F-]+\\s+[0-9a-fA-F-]+\\s+[0-9a-fA-F-]+)','',build_id_free_text)\n",
        "        uuids_free_text = re.sub(r'([0-9a-fA-F-]+\\s*,\\s*[0-9a-fA-F-]+\\s*,\\s*[0-9a-fA-F-]+)','',guids_free_text)\n",
        "        event_id_free_text = re.sub(r'<([^>]+)>','',uuids_free_text)\n",
        "        UUID_free_text = re.sub(r'(?:UUID|GUID|version|id)[\\\\=:\"\\'\\s]*\\b[a-fA-F0-9]{8}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{12}\\b'\n",
        ",'',event_id_free_text,flags=re.IGNORECASE) ##without the prefix so many false positives can be omitted\n",
        "        hex_free_text = re.sub(r'(?:data|address|id)[\\\\=:\"\\'\\s]*\\b0x[0-9a-fA-F]+\\b','',UUID_free_text,flags=re.IGNORECASE) ## deleting hex ids directly can cause issues\n",
        "        ss_free_text = re.sub(r'Screenshot_(\\d{4}[_-]\\d{2}[_-]\\d{2}[_-]\\d{2}[_-]\\d{2}[_-]\\d{2}[_-]\\d{2}[_-]\\w+)','',hex_free_text,flags=re.IGNORECASE)\n",
        "        cleaned_text = ss_free_text\n",
        "        # file_path = \"output.txt\"\n",
        "\n",
        "        # with open(file_path, 'w') as file:\n",
        "        #                 file.write(cleaned_text)\n",
        "        data_dict[j] = {'Issue_id':df['id'][j],'Issue_body':cleaned_text}\n",
        "        # idx = idx+1\n",
        "    \n",
        "\n",
        "\n",
        "cleaned_text_data = pd.DataFrame.from_dict(data_dict, \"index\")\n",
        "cleaned_text_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "###recovered\n",
        "    \n",
        "idx = 0\n",
        "data_dict={}\n",
        "# start = iter*100000\n",
        "# end = (iter+1)*100000\n",
        "for i in regex.index:\n",
        "    print(i,regex['Secret Type'][i]) #, regex['Regular Expression'][i])\n",
        "    # if i%100==0:\n",
        "    #     print(\"checkpoint\")\n",
        "    p = re.compile(regex['Regular Expression'][i])\n",
        "    \n",
        "    # print(\"=====================================================================\")\n",
        "    \n",
        "    for j in df.index:\n",
        "        \n",
        "        cleaned_text = cleaned_text_data.loc[j, 'Issue_body']\n",
        "            # Now you can use 'cleaned_text' for further processing\n",
        "       \n",
        "        matches = re.findall(p,cleaned_text)\n",
        "        for match in set(matches):\n",
        "                data_dict[idx] = {'Type': regex['Secret Type'][i], 'Issue_id':df['id'][j],'Candidate_String':match} #,'Entropy':shannon_entropy(match)}\n",
        "                idx = idx+1\n",
        "    \n",
        "\n",
        "\n",
        "data = pd.DataFrame.from_dict(data_dict, \"index\")\n",
        "print(data.shape)\n",
        "data=data.drop_duplicates(subset=[\"Issue_id\", \"Candidate_String\"], keep='first')\n",
        "data.to_csv('RQ2-issues-with-secret-key-all-26Sept.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "unique_issue_counts = data['Issue_id'].value_counts().reset_index()\n",
        "unique_issue_counts.columns = ['Issue_id', 'count']\n",
        "\n",
        "# Specify the CSV file path where you want to save the data\n",
        "csv_file_path = 'unique_issue_count-16sept.csv'\n",
        "\n",
        "# Save the unique issue ID counts to a CSV file\n",
        "unique_issue_counts.to_csv(csv_file_path, index=False)\n",
        "\n",
        "print(f'Unique issue ID counts saved to {csv_file_path}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 1376734926 this has commit lets see eta ashe naki ar\n",
        "#df[df[\"id\"]==\"1376693330\"].to_csv(\"demo.csv\")\n",
        "df[df[\"id\"]==\"1190623366\"][\"body\"].to_csv(\"demo.csv\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "text = \"Client Version: version.Info{Major:\"\"1\"\", Minor:\"\"16\"\", GitVersion:\"\"v1.16.2\"\", GitCommit:c97fe5036ef3df2967d086711e6c0c405941e14b\"\n",
        "\n",
        "cleaned_text = re.sub(r'commit[ ]?(?:id)?[ ]?[:]?[ ]?([0-9a-f]{40})\\b', '', text, flags=re.IGNORECASE)\n",
        "\n",
        "print(cleaned_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "# Sample text containing file paths\n",
        "test_df = pd.read_csv('demo.csv')\n",
        "\n",
        "text = str(test_df[\"body\"][0]) \n",
        "\n",
        "# Regular expression pattern to match file paths\n",
        "pattern = r\"/[\\w/. :-]+\"\n",
        "\n",
        "# Find all matches in the text\n",
        "print(re.sub(pattern,'', text))\n",
        "\n",
        "# Print the matches\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "text = \"\"\"\n",
        "067bff22-df44-4bf4-926b-30f39549e454,\n",
        "\"\"\"\n",
        "\n",
        "pattern = r'([0-9a-fA-F-]+\\s*,\\s*[0-9a-fA-F-]+\\s*,\\s*[0-9a-fA-F-]+)'\n",
        "print(re.sub(pattern,'',text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "total_instances = 0\n",
        "for i in range(1,8):\n",
        "    temp = pd.read_csv('issues-naive/issues-with-secret-key-'+str(i)+'.csv')\n",
        "    total_instances = total_instances+ temp.shape[0]\n",
        "print(\"RAN ON RAW TEXT: \", total_instances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "temp = pd.read_csv('issues-refined-without-url-and-git-commit/issues-with-secret-key-6.csv')\n",
        "temp.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "text = \"Here is a UUID: afefaf06-34e4-4fa8-9878-0c5bbf572d80 and another UUID: 123e4567-e89b-12d3-a456-426614174000\"\n",
        "pattern = r'\\b[a-fA-F0-9]{8}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{12}\\b'\n",
        "matches = re.findall(pattern, text)\n",
        "\n",
        "for match in matches:\n",
        "    print(match)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "text = \"https://prettier.io/playground/#N4Igxg9gdgLgprEAuEA6ARgQzAawOYBOEArlACYC0hmZAlgjABQACYxMAlAATAA6UXQVyy5CJcki4AbWlDiYCVAjXqxG-IZq4wIXArTwALGABoNWwcwDuh2vC4AGAKRmBFrtdv2WbGFwqOqA4AjE4cru4eAA4QBDCYUhQi+ESkZB6+Ee7MMXEJSdgp4unBDs7mghwA3PwAvvwgJiAQUTC00ADOyKAKRFYACgoIXSgJVpgAnl1N6Mq4cDAAypgAtnAAMrJwyABmCR1wM3M4C4tR2LJ4yDAExIcgcCvocGRkL+uYUHjEmHhwAGKxFaYGBtL7IECYdgQRogYwrKQAdS8cA65zAcEWwzstAAbnYJhCwB1piBZAc4v1lHhgbt9vcAFYdAAei0uUjgAEViBB4HSpAcmucCBSIRySbCovpYIjaGQYIZkAAOBxCogHRHKKIQqWouAEXHbJoARx58CpLRGkI6FDkLxesIIcFNtCdVN+tKQewF9wOK1o11uvvZXLN2y99Ka8XQsvliqQACYo8paDIvgBhCArT0PDoAVlhxAOABVMOgRt7BSBcXcAJLkBiLMD6VoAQXIixgEw5-IOtVqQA\"\n",
        "\n",
        "# Regex pattern to detect URLs with fragment identifiers\n",
        "# pattern = r'https?://\\S+#\\S+'\n",
        "pattern = r'https?://[^\\s#]+#[A-Za-z0-9\\-]+'\n",
        "matches = re.findall(pattern, text)\n",
        "\n",
        "for match in matches:\n",
        "    print(match)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "text = \" Module libdouble-conversion.so.3 with build-id:  d162eb67b00f523a3f146b1077ae00fe04d5fb85\"\n",
        "# Define the regex pattern (case-insensitive)\n",
        "pattern = r'build-id\\s*[:]?\\s*([a-fA-F0-9]+)'\n",
        "\n",
        "# Find all matches in the text\n",
        "matches = re.findall(pattern, text)\n",
        "\n",
        "# Print the captured build-ids\n",
        "for match in matches:\n",
        "    print(\"Found build-id:\", match)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "text = \"0x10405c000 - 0x10436bfff +com.utmapp.UTM (2.2.4 - 36) <F55AA24B-A6DD-33E5-880C-8BBE335FAC5D> /Applications/UTM.app/Contents/MacOS/UTM\"\n",
        "pattern = r'([^>]+)'\n",
        "matches = re.findall(pattern, text)\n",
        "\n",
        "for match in matches:\n",
        "    print(match)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "text = \"Here is a screenshot: Screenshot_2022-04-20-22-07-32-23_307f4184460b001ebff3ecdd8a4bcf05 and another one Screenshot_2022_11_30_10_15_20_88_1a2b3c4d5e6f7g8h.\"\n",
        "matches = re.findall(r'Screenshot_\\d{4}_\\d{2}_\\d{2}_\\d{2}_\\d{2}_\\d{2}_\\d{2}_\\w{16}', text)\n",
        "\n",
        "print(matches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "text = \"\"\"\n",
        "GUIDs:        f6b5141d-eeb0-5ff1-b8de-ee4f02b222b7\n",
        "                       2c4d586a-a2a6-5957-9427-768add598121\n",
        "                       ebd96940-fa49-5cb1-b1a1-aa2d4dea1416\n",
        "                       5108e726-44a6-5eca-bd1a-fbbdabbe7bc1\n",
        "                       31d41b9b-361a-50ad-8bea-8dad3339fa04\n",
        "\"\"\"\n",
        "\n",
        "pattern = r'GUIDs:\\s+([0-9a-fA-F-]+\\s+[0-9a-fA-F-]+\\s+[0-9a-fA-F-]+)'\n",
        "matches = re.search(pattern, text)\n",
        "\n",
        "if matches:\n",
        "    captured_string = matches.group(0)\n",
        "    print(captured_string)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "things I need to clean further\n",
        "1. \"sha256:a812164ceb48cb62c3217bd6245274e693c624cc2ac0c1b11b4cea96dab054dd\"  \n",
        "2. 3 root root 4096 Oct 16  2020 11af3aea-a3a6-490d-b4e8-871f7bbd1c31                                                \n",
        "3. git-tree-sha1 = \"\"e1ba79094cae97b688fb42d31cbbfd63a69706e4\"\"\n",
        "4. uuid = \"\"4c555306-a7a7-4459-81d9-ec55ddd5c99a\"\"   \n",
        "5.        0x10405c000 -        0x10436bfff +com.utmapp.UTM (2.2.4 - 36) <F55AA24B-A6DD-33E5-880C-8BBE335FAC5D> /Applications/UTM.app/Contents/MacOS/UTM\n",
        "6. build-id 2845e847d99e2c338fc8eef599b018e707c5e811"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
