{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SPs0eg7jqSVN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Pzyky-DBLULR"
      },
      "outputs": [],
      "source": [
        "RANDOM_SEED = 43"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41ElWGJ17XER",
        "outputId": "9c527f0c-01da-477a-e221-5cc88ef1dce9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ahmed\\AppData\\Local\\Temp\\ipykernel_20320\\2050619644.py:1: DtypeWarning: Columns (0,1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(\"dataset/nlbse-2023-issue-report.csv\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(745732, 6)\n",
            "(726503, 6)\n",
            "(25451, 5)\n",
            "Index(['Issue_id', 'candidate_string', 'label', 'text'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"dataset/nlbse-2023-issue-report.csv\")\n",
        "df.shape\n",
        "df = df[df['labels']=='bug']\n",
        "print(df.shape)\n",
        "df_unique = df.drop_duplicates(subset='id', keep='first')\n",
        "print(df_unique.shape)\n",
        "df = df_unique\n",
        "df[\"id\"] = df[\"id\"].astype(int)\n",
        "df_selected = df[['id','body']]\n",
        "\n",
        "concatenated_df = pd.read_csv(\"dataset/Manual-labelled-data-25K.csv\")\n",
        "concatenated_df_selected = concatenated_df[['Issue_id','Candidate_String', 'is_secret_human_label']]\n",
        "\n",
        "# Rename columns for consistency\n",
        "df_selected = df_selected.rename(columns={'body': 'text'})\n",
        "concatenated_df_selected = concatenated_df_selected.rename(columns={'Candidate_String': 'candidate_string', 'is_secret_human_label': 'label'})\n",
        "\n",
        "# Merge the two DataFrames on a common key, for example, 'id'\n",
        "# Adjust the merge key as needed based on your data\n",
        "merged_df = concatenated_df_selected.merge(df_selected, left_on='Issue_id', right_on='id')\n",
        "print(merged_df.shape)\n",
        "columns_to_remove = ['id']\n",
        "merged_df.drop(columns=columns_to_remove, inplace=True)\n",
        "print(merged_df.columns)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Preprocessing Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biXbNcNH6Ox4",
        "outputId": "6ee66d60-ec7d-4e3d-f92b-d0c84bd2ed5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mismatch: 1807\n",
            "(1807, 4)\n",
            "Ok: 23644\n",
            "(23644, 4)\n"
          ]
        }
      ],
      "source": [
        "#print(merged_df.size)\n",
        "#print(merged_df.shape[0])\n",
        "#print(type(merged_df))\n",
        "#print(merged_df.head())\n",
        "preprocessed_df=None\n",
        "unprocessed_df = None\n",
        "count=0\n",
        "inverse_count=0\n",
        "for i in range(merged_df.shape[0]):\n",
        "  main_string=merged_df['text'][i]\n",
        "  substring=merged_df['candidate_string'][i]\n",
        "  if main_string.find(substring)== -1 :\n",
        "    count+=1\n",
        "    if unprocessed_df is None:\n",
        "      unprocessed_df = pd.DataFrame(merged_df.iloc[i, :]).transpose()\n",
        "    else:\n",
        "      unprocessed_df = pd.concat([unprocessed_df, pd.DataFrame(merged_df.iloc[i, :]).transpose()], ignore_index=True)\n",
        "  else:\n",
        "    inverse_count+=1\n",
        "    # Append the row to preprocessed_df\n",
        "    if preprocessed_df is None:\n",
        "      preprocessed_df = pd.DataFrame(merged_df.iloc[i, :]).transpose()\n",
        "    else:\n",
        "      preprocessed_df = pd.concat([preprocessed_df, pd.DataFrame(merged_df.iloc[i, :]).transpose()], ignore_index=True)\n",
        "\n",
        "print(\"Mismatch: \"+str(count))\n",
        "print(unprocessed_df.shape)\n",
        "#print(unprocessed_df.head())\n",
        "\n",
        "print(\"Ok: \"+str(inverse_count))\n",
        "print(preprocessed_df.shape)\n",
        "#print(preprocessed_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "for j in unprocessed_df.index:\n",
        "        # if df[\"id\"][j] != \"1165939311\":\n",
        "        #         continue\n",
        "        input_string =    str(df[df[\"id\"]==unprocessed_df[\"Issue_id\"][j]][\"body\"])    \n",
        "        input_string = re.sub(r'[\\'\"\\│]', '', input_string)\n",
        "        dir_list_clean = re.sub(r'drwx[-\\s]*\\d+\\s+\\w+\\s+\\w+\\s+\\d+\\s+\\w+\\s+\\d+\\s+[0-9a-fA-F-]+.*','',input_string)\n",
        "        shell_code_free_text = re.sub(r'```shell([^`]+)```','',dir_list_clean,flags=re.IGNORECASE)\n",
        "        shell_code_free_text = re.sub(r'```Shell\\s*\"([^\"]*)\"\\s*```','',shell_code_free_text,flags=re.IGNORECASE)\n",
        "        # saved_game_free_text = re.sub(r'```([^`]+)```','',shell_code_free_text) #etay jhamela hobe\n",
        "        saved_game_free_text = re.sub(r'<details><summary>Saved game</summary>\\n\\n```(.*?)```', '', shell_code_free_text)\n",
        "        remove_packages = re.sub(r'(\\w+\\.)+\\w+','',saved_game_free_text)\n",
        "        java_exp_free_text = re.sub(r'at\\s[\\w.$]+\\.([\\w]+)\\(([^:]+:\\d+)\\)','',remove_packages)\n",
        "        # url_free_text= re.sub(https?://[^\\s#]+#[A-Za-z0-9\\-]+,'', java_exp_free_text, flags=re.IGNORECASE)\n",
        "        url_with_fragment_text= re.sub(r'https?://[^\\s#]+#[A-Za-z0-9\\-\\=\\+]+','', java_exp_free_text, flags=re.IGNORECASE)\n",
        "        url_free_text= re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '',url_with_fragment_text)\n",
        "        commit_free_text= re.sub(r'commit[ ]?(?:id)?[ ]?[:]?[ ]?([0-9a-f]{40})\\b', '', url_free_text, flags=re.IGNORECASE)\n",
        "        file_path_free_text = re.sub(r\"/[\\w/. :-]+\",'',commit_free_text)\n",
        "        file_path_free_text = re.sub( r'(/[^/\\s]+)+','',file_path_free_text)\n",
        "        sha256_free_text = re.sub(r'sha256\\s*[:]?[=]?\\s*[a-fA-F0-9]{64}','',file_path_free_text)\n",
        "        sha1_free_text = re.sub(r'git-tree-sha1\\s*=\\s*[a-fA-F0-9]+','',sha256_free_text)\n",
        "        build_id_free_text = re.sub(r'build-id\\s*[:]?[=]?\\s*([a-fA-F0-9]+)','',sha1_free_text)\n",
        "        guids_free_text = re.sub(r'GUIDs:\\s+([0-9a-fA-F-]+\\s+[0-9a-fA-F-]+\\s+[0-9a-fA-F-]+)','',build_id_free_text)\n",
        "        uuids_free_text = re.sub(r'([0-9a-fA-F-]+\\s*,\\s*[0-9a-fA-F-]+\\s*,\\s*[0-9a-fA-F-]+)','',guids_free_text)\n",
        "        event_id_free_text = re.sub(r'<([^>]+)>','',uuids_free_text)\n",
        "        UUID_free_text = re.sub(r'(?:UUID|GUID|version|id)[\\\\=:\"\\'\\s]*\\b[a-fA-F0-9]{8}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{12}\\b'\n",
        ",'',event_id_free_text,flags=re.IGNORECASE) ##without the prefix so many false positives can be omitted\n",
        "        hex_free_text = re.sub(r'(?:data|address|id)[\\\\=:\"\\'\\s]*\\b0x[0-9a-fA-F]+\\b','',UUID_free_text,flags=re.IGNORECASE) ## deleting hex ids directly can cause issues\n",
        "        ss_free_text = re.sub(r'Screenshot_(\\d{4}[_-]\\d{2}[_-]\\d{2}[_-]\\d{2}[_-]\\d{2}[_-]\\d{2}[_-]\\d{2}[_-]\\w+)','',hex_free_text,flags=re.IGNORECASE)\n",
        "        cleaned_text = ss_free_text\n",
        "\n",
        "        #unprocessed_df.loc[j, 'Issue_id']=cleaned_text\n",
        "        unprocessed_df.loc[j,'Issue_id'] = str(df[df[\"id\"]==unprocessed_df[\"Issue_id\"][j]][\"body\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aInt7Yv_HJdG",
        "outputId": "730fae85-7ab8-4e35-96a1-208c1dbe1a88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mismatch: 1807\n",
            "Ok: 0\n",
            "                                            Issue_id  \\\n",
            "0  135024    ### Did you clear cache before openi...   \n",
            "1  579753    ### Update disclaimer\\n\\n- [x] Yes, ...   \n",
            "2  1038525    ### Describe the bug\\r\\n\\r\\nDeployi...   \n",
            "3  1024594    **[Dario Scoppelletti](https://jira...   \n",
            "4  720705    用户分级scopes字段不管用\\r\\n`package org.spri...   \n",
            "\n",
            "                                    candidate_string label  \\\n",
            "0  showTimerProgress:false,smoothCaret:true,quick...     0   \n",
            "1                           c__DisplayClass24_0.b__1     0   \n",
            "2                                   ;pw=();print((pw     0   \n",
            "3                         xAC\\xED\\x00\\x05sr\\x00\\\\x95     0   \n",
            "4                             serviceToken).toString     0   \n",
            "\n",
            "                                                text  \n",
            "0  ### Did you clear cache before opening an issu...  \n",
            "1  ### Update disclaimer\\n\\n- [x] Yes, I have che...  \n",
            "2  ### Describe the bug\\r\\n\\r\\nDeploying with the...  \n",
            "3  **[Dario Scoppelletti](https://jira.spring.io/...  \n",
            "4  用户分级scopes字段不管用\\r\\n`package org.springblade.mo...  \n"
          ]
        }
      ],
      "source": [
        "count=0\n",
        "inverse_count=0\n",
        "\n",
        "for i in range(unprocessed_df.shape[0]):\n",
        "  #print(i)\n",
        "  main_string=unprocessed_df['text'][i]\n",
        "  substring=unprocessed_df['candidate_string'][i]\n",
        "  #print(main_string.find(substring))\n",
        "  if main_string.find(substring)!=-1:\n",
        "    count+=1\n",
        "  else:\n",
        "    inverse_count+=1\n",
        "print(\"Mismatch: \"+str(inverse_count))\n",
        "print(\"Ok: \"+str(count))\n",
        "print(unprocessed_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# processed_df = pd.concat([unprocessed_df,preprocessed_df])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Setting Context Window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjYKTmpsEbWp",
        "outputId": "655f9d60-a5fe-4180-c5d0-c06cb0009a73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(25451, 5)\n",
            "0    pute-1.amazonaws.com> SSH: EXEC ssh -vvv -o Co...\n",
            "1    mplete the following information):**\\r\\n - Dev...\n",
            "2                                                 None\n",
            "3    ### What happened?\\n\\ngws-ingress services kee...\n",
            "4    ain() {\\r\\n  runApp(const MyApp());\\r\\n}\\r\\n\\r...\n",
            "Name: modified_text, dtype: object\n"
          ]
        }
      ],
      "source": [
        "def create_context_window(text, target_string, window_size=200):\n",
        "\n",
        "    target_index = text.find(target_string)\n",
        "    #print(target_index)\n",
        "\n",
        "    if target_index != -1:\n",
        "        start_index = max(0, target_index - window_size)\n",
        "        end_index = min(len(text), target_index + len(target_string) + window_size)\n",
        "        context_window = text[start_index:end_index]\n",
        "        return context_window\n",
        "\n",
        "    return None\n",
        "\n",
        "# Apply the create_context_window function to each row in the DataFrame\n",
        "preprocessed_df['modified_text'] = preprocessed_df.apply(lambda row: create_context_window(row['text'], row['candidate_string']), axis=1)\n",
        "print(preprocessed_df.shape)\n",
        "print(preprocessed_df['modified_text'].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7rJok_YAvp4",
        "outputId": "26925f65-3b75-4fec-99f5-89fd498bf8db"
      },
      "outputs": [],
      "source": [
        "#pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "1QdUHs7SqSVP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification, AdamW\n",
        "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJFaCfmEVXtZ"
      },
      "source": [
        "Setting Seeds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "bGrm5hStVbT-"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(RANDOM_SEED)\n",
        "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LIRjSxkJp8u"
      },
      "source": [
        "## Processing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "sR3hKXYMKZyQ"
      },
      "outputs": [],
      "source": [
        "# Load and prepare your dataset\n",
        "# You will have two lists: X_text (text bodies) and X_candidate (candidate strings)\n",
        "\n",
        "# Encode text bodies and candidate strings separately\n",
        "X_issue_ids = preprocessed_df['Issue_id'].tolist()\n",
        "X_text = preprocessed_df['text'].tolist()  # Convert the 'text' column to a list of strings\n",
        "X_candidate = preprocessed_df['candidate_string'].tolist()  # Convert the 'candidate_string' column to a list of strings\n",
        "Y_labels = preprocessed_df['label'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "iv3W_eo_JOR0"
      },
      "outputs": [],
      "source": [
        "# X_text = X_text[0:100]\n",
        "# X_candidate = X_candidate[0:100]\n",
        "# Y_labels = Y_labels[0:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "zr5Y3GUSKf2h"
      },
      "outputs": [],
      "source": [
        "split_ratio = 0.2\n",
        "X_text_train, X_text_test, X_candidate_train, X_candidate_test, Y_labels_train, Y_labels_test,X_issue_ids_train,X_issue_ids_test = train_test_split(\n",
        "        X_text, X_candidate, Y_labels,X_issue_ids, test_size=split_ratio, random_state=RANDOM_SEED\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKusxQhzXS_C",
        "outputId": "bf34a3ee-ecd7-44cb-f927-567bce584c13"
      },
      "outputs": [],
      "source": [
        "#type(Y_labels_test), len(Y_labels_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6qO6Q-lKqtn",
        "outputId": "8919cf03-92e3-40d5-aa54-9bd350cf3075"
      },
      "outputs": [],
      "source": [
        "#print(len(X_text_train), len(X_text_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ka5uuHPfNrQG",
        "outputId": "aa52238c-211f-418f-b787-052742fb42b8"
      },
      "outputs": [],
      "source": [
        "#!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "FBJTaaNdIFnK"
      },
      "outputs": [],
      "source": [
        "# Tokenize text bodies and candidate strings separately\n",
        "def encode_texts(texts):\n",
        "    encodings = tokenizer(texts, padding=True, truncation=True, return_tensors='pt', max_length=512)\n",
        "    return encodings\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "k7nKyRaYIZgQ"
      },
      "outputs": [],
      "source": [
        "text_body_encodings = encode_texts(X_text_train)\n",
        "candidate_encodings = encode_texts(X_candidate_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkNYrdDqJd2G"
      },
      "outputs": [],
      "source": [
        "# Define a custom dataset class\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, text_encodings, candidate_encodings, labels):\n",
        "        self.text_encodings = text_encodings\n",
        "        self.candidate_encodings = candidate_encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx): #it works fine for training\n",
        "        text_input_ids = self.text_encodings['input_ids'][idx]\n",
        "        text_attention_mask = self.text_encodings['attention_mask'][idx]\n",
        "        candidate_input_ids = self.candidate_encodings['input_ids'][idx]\n",
        "        candidate_attention_mask = self.candidate_encodings['attention_mask'][idx]\n",
        "        label = torch.tensor(self.labels[idx])\n",
        "\n",
        "        return text_input_ids, text_attention_mask, candidate_input_ids, candidate_attention_mask, label\n",
        "\n",
        "# train_dataset = CustomDataset(text_body_encodings, candidate_encodings, Y_train)\n",
        "# test_dataset = CustomDataset(X_test_text, X_test_candidate, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ir_QkCY9L1Nj",
        "outputId": "63207ba3-96fe-446a-bd5c-9011a112db70"
      },
      "outputs": [],
      "source": [
        "np.unique(np.asarray(Y_labels_train), return_counts=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBwsD63v5bR8",
        "outputId": "73d056b6-a320-4cd6-c7a8-298d4ce8cf44"
      },
      "outputs": [],
      "source": [
        "print(type(Y_labels_train), len(Y_labels_train))\n",
        "Y = np.array(Y_labels_train)\n",
        "Y_ =Y.astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDHNpnbvIZmc"
      },
      "outputs": [],
      "source": [
        "train_dataset = CustomDataset(text_body_encodings, candidate_encodings, Y_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJ6epPNuIZpV",
        "outputId": "3a2fee2f-e2db-4c8a-95a7-edc6d997df53"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=False)\n",
        "print(len(train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCvR5aYpbrlN",
        "outputId": "248722a9-9e31-4729-a663-bf492e2d597c"
      },
      "outputs": [],
      "source": [
        "type(np.array(Y_labels_train))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzHAnu60Qmza",
        "outputId": "83553c61-1e68-4a6e-c20b-4008e2bfb4a4"
      },
      "outputs": [],
      "source": [
        "\n",
        "torch.cuda.is_available()\n",
        "torch.cuda.get_device_name(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJnTSV3KMEAe"
      },
      "source": [
        "## Fine-tune RoBERTa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEg15qXY89lD",
        "outputId": "d5a633a9-e818-4299-f2c9-b714ce027557"
      },
      "outputs": [],
      "source": [
        "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=2)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Training Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDQheDYfqSVP",
        "outputId": "1c0f2fca-295e-42ed-fac3-4b3e59bc8c24"
      },
      "outputs": [],
      "source": [
        "# Fine-tune RoBERTa\n",
        "\n",
        "\n",
        "#optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
        "\n",
        "\n",
        "\n",
        "# learning_rate = 1e-3\n",
        "# momentum = 0.9  # If using SGD with momentum\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
        "\n",
        "\n",
        "# learning_rate = 1e-5\n",
        "# optimizer = torch.optim.Adagrad(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "\n",
        "learning_rate = 1e-5\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "# Training loop\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    c = 1\n",
        "    # for batch in train_loader:\n",
        "    #     print(\"batch: \",c)\n",
        "    #     text_input_ids, text_attention_mask, candidate_input_ids, candidate_attention_mask, labels = batch\n",
        "    #     text_input_ids, text_attention_mask, candidate_input_ids, candidate_attention_mask, labels = text_input_ids.to(device), text_attention_mask.to(device), candidate_input_ids.to(device), candidate_attention_mask.to(device), labels.to(device)\n",
        "\n",
        "    #     outputs = model(input_ids=text_input_ids, attention_mask=text_attention_mask, labels=labels)\n",
        "    #     loss = outputs.loss\n",
        "    #     loss.backward()\n",
        "    #     optimizer.step()\n",
        "    #     optimizer.zero_grad()\n",
        "    for batch in train_loader:\n",
        "        print(\"epoch: \",epoch)\n",
        "        print(\"batch: \", c)\n",
        "        text_input_ids, text_attention_mask, candidate_input_ids, candidate_attention_mask, labels = batch\n",
        "\n",
        "        # Ensure that you access the tensors with integer indices, not string keys\n",
        "        text_input_ids, text_attention_mask, candidate_input_ids, candidate_attention_mask, labels = (\n",
        "            text_input_ids.to(device),\n",
        "            text_attention_mask.to(device),\n",
        "            candidate_input_ids.to(device),\n",
        "            candidate_attention_mask.to(device),\n",
        "            labels.to(device)\n",
        "        )\n",
        "        with torch.no_grad():\n",
        "            for module in model.modules():\n",
        "                if isinstance(module, torch.nn.Dropout):\n",
        "                    module.p = 0  # Set dropout probability to 0\n",
        "\n",
        "        # The rest of your training code\n",
        "        outputs = model(input_ids=text_input_ids.type(torch.LongTensor).cuda(), attention_mask=text_attention_mask.type(torch.LongTensor).cuda(), labels=labels.type(torch.LongTensor).cuda())\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        c = c+1\n",
        "\n",
        "# Evaluate the model\n",
        "model.eval()\n",
        "# with torch.no_grad():\n",
        "#     for batch in test_loader:\n",
        "#         text_input_ids, text_attention_mask, candidate_input_ids, candidate_attention_mask, labels = batch\n",
        "#         text_input_ids, text_attention_mask, candidate_input_ids, candidate_attention_mask, labels = text_input_ids.to(device), text_attention_mask.to(device), candidate_input_ids.to(device), candidate_attention_mask.to(device), labels.to(device)\n",
        "\n",
        "#         outputs = model(input_ids=text_input_ids, attention_mask=text_attention_mask)\n",
        "#         predicted_labels = torch.argmax(outputs.logits, dim=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Saving and loading model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vg7afD7g04_B"
      },
      "outputs": [],
      "source": [
        "# Save the model to a file\n",
        "model_path = \"models/local_roberta_model_10epoch_lr1e-5_torchrmsprop_cntxt200_data25k.pth\"\n",
        "torch.save(model.state_dict(), model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbQ7oZea1OXr",
        "outputId": "65fd5d83-aaa6-4728-9d28-b328940c3868"
      },
      "outputs": [],
      "source": [
        "# Load the model from the file\n",
        "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=2)  # Replace with your model configuration\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model.eval()  # Set the model to evaluation mode for inference\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ur76fhhKNy4v"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CN3ZGOX3NzhW"
      },
      "source": [
        "## Test Dataset here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbzAtcZnNy6x"
      },
      "outputs": [],
      "source": [
        "text_body_encodings_test = encode_texts(X_text_test)\n",
        "candidate_encodings_test = encode_texts(X_candidate_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVx4sHGDz6xn",
        "outputId": "27847ccd-2112-4cb0-b2da-b6ad3cc3bd31"
      },
      "outputs": [],
      "source": [
        "print(type(Y_labels_test), len(Y_labels_test))\n",
        "Y_test = np.array(Y_labels_test)\n",
        "print(type(Y_test), len(Y_test))\n",
        "print(Y_test[:4085])\n",
        "#for i in range(len(Y_test)):\n",
        "#  if Y_test[i] ==  ' AWS4-HMAC-SHA256 Credential':\n",
        "#    Y_test[i]='1'\n",
        "Y_test_ =Y_test.astype(int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aG5GLrYENy9X"
      },
      "outputs": [],
      "source": [
        "\n",
        "test_dataset = CustomDataset(text_body_encodings_test, candidate_encodings_test, Y_test_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vtloKtZNzAA"
      },
      "outputs": [],
      "source": [
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Testing model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwjL3cPjNzCS",
        "outputId": "9ed1176d-a4ea-49ff-f983-f77fcc2b2b83"
      },
      "outputs": [],
      "source": [
        "model.to(device)\n",
        "model.eval()  # Set the model in evaluation mode\n",
        "c=0\n",
        "predicted_labels_list = []\n",
        "with torch.no_grad():\n",
        "\n",
        "    for batch in test_loader:\n",
        "        print(\"Batch %d\"%c)\n",
        "        c+=1\n",
        "\n",
        "        text_input_ids, text_attention_mask, candidate_input_ids, candidate_attention_mask, labels = batch\n",
        "\n",
        "        # Move tensors to the device\n",
        "        text_input_ids, text_attention_mask, candidate_input_ids, candidate_attention_mask, labels = (\n",
        "            text_input_ids.to(device),\n",
        "            text_attention_mask.to(device),\n",
        "            candidate_input_ids.to(device),\n",
        "            candidate_attention_mask.to(device),\n",
        "            labels.to(device)\n",
        "        )\n",
        "\n",
        "        # Perform inference\n",
        "\n",
        "        outputs = model(input_ids=text_input_ids.type(torch.LongTensor).cuda(), attention_mask=text_attention_mask.type(torch.LongTensor).cuda())\n",
        "        predicted_labels = torch.argmax(outputs.logits, dim=1)\n",
        "\n",
        "        # print(f\"predicted_labels: {predicted_labels}\")\n",
        "        predicted_labels_list.append(predicted_labels[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvGeNmx4P0m4"
      },
      "outputs": [],
      "source": [
        "predicted_labels_list_output = [f.cpu().numpy().tolist() for f in predicted_labels_list]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRQSGv_W3yg6",
        "outputId": "cf91d970-22aa-4787-dcc5-776bc4d364c2"
      },
      "outputs": [],
      "source": [
        "print(len(X_candidate_test))\n",
        "print(len(Y_labels_test))\n",
        "print(len(predicted_labels_list_output))\n",
        "print(len(X_issue_ids_test))\n",
        "print(len(X_text_test))\n",
        "test_text=[]\n",
        "test_id=[]\n",
        "test_can=[]\n",
        "test_label=[]\n",
        "test_pred=[]\n",
        "for i in range(len(Y_labels_test)):\n",
        "  if Y_labels_test[i] == '1':\n",
        "    test_text.append((X_text_test[i].replace(\"\\n\", \"\")).replace(\"\\r\", \"\"))\n",
        "    test_id.append(X_issue_ids_test[i])\n",
        "    test_can.append(X_candidate_test[i])\n",
        "    test_label.append(Y_labels_test[i])\n",
        "    test_pred.append(predicted_labels_list_output[i])\n",
        "\n",
        "\n",
        "dict = {'Issue Id':test_id ,'Body':test_text,'Candidate String':test_can,'Actual Label': test_label, 'Predicted Label': test_pred}\n",
        "df = pd.DataFrame(dict)\n",
        "df.to_csv('positive_data.csv', sep=',', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "Ripqkjr8QNIz",
        "outputId": "30e2f151-8980-475b-b009-e35fbe122e51"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "cm = confusion_matrix(Y_test_, predicted_labels_list_output, labels=[0,1])\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=[0,1])\n",
        "disp.plot()\n",
        "plt.title(\"AdamW,contextwindow,LR=1e-5\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mkpwcXfP0pI"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3F-zLD2jQcWr"
      },
      "outputs": [],
      "source": [
        "def get_metrics(y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"f1\": f1,\n",
        "        \"recall\": recall\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGV_IGShPBaQ"
      },
      "outputs": [],
      "source": [
        "metrics = get_metrics(Y_test_, predicted_labels_list_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Normal Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_yDVM0OO6tl",
        "outputId": "5aeeccba-c4d4-4e85-bdff-159197a08095"
      },
      "outputs": [],
      "source": [
        "metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_W3HSHsV1uL"
      },
      "outputs": [],
      "source": [
        "def get_minority_metrics(y_true, y_pred, minority_class_label):\n",
        "    # Convert lists to NumPy arrays\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    # Calculate the metrics for the minority class\n",
        "    minority_indices = np.where(y_true == minority_class_label)\n",
        "    y_true_minority = y_true[minority_indices]\n",
        "    y_pred_minority = y_pred[minority_indices]\n",
        "\n",
        "    # Calculate precision, recall, and F1-score for the minority class\n",
        "    minority_precision = precision_score(y_true_minority, y_pred_minority)\n",
        "    minority_recall = recall_score(y_true_minority, y_pred_minority)\n",
        "    minority_f1 = f1_score(y_true_minority, y_pred_minority)\n",
        "\n",
        "    return {\n",
        "        'Minority Precision': minority_precision,\n",
        "        'Minority Recall': minority_recall,\n",
        "        'Minority F1-Score': minority_f1\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URM1OuBkW1bX"
      },
      "outputs": [],
      "source": [
        "minority_metrics = get_minority_metrics(Y_test_, predicted_labels_list_output, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Minority Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfNAPiwsW1gR",
        "outputId": "35a079ce-bece-436f-87a8-88c04adb3e2e"
      },
      "outputs": [],
      "source": [
        "minority_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ge_149hDbOHD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdrXjdHzbN8R"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-Tejuk5bNr5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUEPKrm9bfso"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0sRMTbybfkd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPstW4evWKDh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYL37RmPWKGJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aB9Wz-kKWKIu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v29Xv4BMWIzj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0D7L7JrLWI16"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQanqWOVWI4S"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tq0xzS8AWI6l"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZD_Iyg5LWI9d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
